# ğŸ“Š Metrics Display - Quickstart

## ğŸš€ Schneller Start

### Backend Kompilierung
```bash
cd backend/perplexity-service
mvn clean compile
```

Status: âœ… BUILD SUCCESS

### Frontend Integration
Die MetricsCard ist bereits in `ChatInterface.vue` integriert.

## ğŸ“Š Was wird angezeigt?

Nach jeder API-Antwort erscheint eine MetricsCard mit:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“Š Response Metrics                  â–¼  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ¤– Model: anthropic/claude-3.5-sonnet  â”‚
â”‚ ğŸ”Œ Provider: openrouter                â”‚
â”‚                                         â”‚
â”‚ ğŸ“¥ Input Tokens: 150                   â”‚
â”‚ ğŸ“¤ Output Tokens: 250                  â”‚
â”‚ ğŸ“Š Total Tokens: 400                   â”‚
â”‚                                         â”‚
â”‚ ğŸ’° Cost: $0.004200                     â”‚
â”‚ â±ï¸ Response Time: 1234ms               â”‚
â”‚                                         â”‚
â”‚ Token Distribution                     â”‚
â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ (37.5% / 62.5%)   â”‚
â”‚ ğŸ“¥ 150 ğŸ“¤ 250                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Technische Details

### Backend-Ã„nderungen
1. **ResponseMetrics.java** - DTO mit Token-, Kosten- und Zeit-Informationen
2. **ChatResponse.java** - ErhÃ¤lt `metrics` Property
3. **OpenRouterToolClient.java** - Neue Methode `requestCompletionWithMetrics()`
4. **AgentService.java** - Sammelt Metriken und gibt sie zurÃ¼ck

### Frontend-Ã„nderungen
1. **MetricsCard.vue** - Neue Komponente fÃ¼r Metriken-Anzeige
2. **ChatInterface.vue** - Integriert MetricsCard und speichert Metriken
3. **types.ts** - ResponseMetrics-Type definiert
4. **chatService.ts** - UnterstÃ¼tzt model-Parameter

## ğŸ¯ Features

âœ… **Token-Tracking**: Input, Output, Total  
âœ… **Kosten-Berechnung**: Automatisch aus ModelPricingConfig  
âœ… **Response-Zeit**: In Millisekunden  
âœ… **Model-Info**: Zeigt welches Model verwendet wurde  
âœ… **Visuelle Darstellung**: Token-Verteilungs-Balken  
âœ… **Collapsible**: Kann ein-/ausgeklappt werden  
âœ… **Responsive**: Funktioniert auf allen GerÃ¤ten  
âœ… **Smooth Animations**: Slide-Down Effekt  

## ğŸ“ˆ Datenfluss

```
User sendet Nachricht
         â†“
Backend berechnet Antwort
         â†“
Sammelt Metrics:
  â€¢ inputTokens
  â€¢ outputTokens
  â€¢ cost (berechnet)
  â€¢ responseTimeMs
  â€¢ model
  â€¢ provider
         â†“
ChatResponse mit metrics
         â†“
Frontend speichert Metriken
         â†“
MetricsCard rendert Metriken
```

## ğŸ¨ Design-Highlights

- **Gradient Background**: Blau (#f5f7fa â†’ #c3cfe2)
- **Input-Balken**: Blau (#3498db â†’ #2980b9)
- **Output-Balken**: GrÃ¼n (#2ecc71 â†’ #27ae60)
- **Cost-Highlight**: HellgrÃ¼n Background
- **Hover-Effect**: ErhÃ¶hte Schatten + Transform

## ğŸ“‹ API Response Format

```json
{
  "reply": "Dies ist die KI-Antwort...",
  "toolName": "OpenRouterToolClient",
  "timestamp": "2025-12-09T22:00:00Z",
  "metrics": {
    "inputTokens": 150,
    "outputTokens": 250,
    "totalTokens": 400,
    "cost": 0.00420,
    "responseTimeMs": 1234,
    "model": "anthropic/claude-3.5-sonnet",
    "provider": "openrouter"
  }
}
```

## ğŸ’¡ Tipps fÃ¼r Benutzer

1. **Kosten vergleichen**: Verschiedene Modelle haben unterschiedliche Preise
   - Gemma 3N: sehr gÃ¼nstig
   - Claude 3.5 Sonnet: gutes VerhÃ¤ltnis
   - Claude Opus: teuer aber sehr mÃ¤chtig

2. **Token-Limits beachten**: GrÃ¶ÃŸere Modelle kosten mehr
   - Input-Tokens: AbhÃ¤ngig von Frage-LÃ¤nge
   - Output-Tokens: AbhÃ¤ngig von Antwort-LÃ¤nge

3. **Response-Zeit**: Hilft zu verstehen, wie lange API braucht
   - Typisch: 1-3 Sekunden
   - AbhÃ¤ngig von Modell und KomplexitÃ¤t

4. **Metriken einklappen**: Wenn nicht benÃ¶tigt, Platz sparen

## ğŸ” Debugging

### Console prÃ¼fen (F12)
```javascript
// Du siehst:
ğŸ“Š Metrics stored for message: {
  inputTokens: 150,
  outputTokens: 250,
  totalTokens: 400,
  cost: 0.00420,
  responseTimeMs: 1234,
  model: "anthropic/claude-3.5-sonnet",
  provider: "openrouter"
}
```

### Network prÃ¼fen (DevTools â†’ Network)
1. Sende eine Nachricht
2. Klicke auf POST `/api/chat`
3. Response Tab â†’ Siehst JSON mit metrics

## ğŸ“ Beispiel-Szenarios

### Scenario 1: Kurze Frage zu Claude 3.5 Sonnet
```
Input: "Was ist Python?"
Metriken:
  Input: 10 tokens (~0.00003$)
  Output: 100 tokens (~0.0015$)
  Total: ~0.00153$
  Time: 800ms
```

### Scenario 2: Lange Frage zu GPT-4o
```
Input: "Schreib mir einen kompletten Blog-Post Ã¼ber..."
Metriken:
  Input: 500 tokens (~0.0025$)
  Output: 2000 tokens (~0.03$)
  Total: ~0.0325$
  Time: 3500ms
```

### Scenario 3: GÃ¼nstige Anfrage zu Mistral Small
```
Input: "Hallo!"
Metriken:
  Input: 5 tokens (~0.0000007$)
  Output: 50 tokens (~0.000021$)
  Total: ~0.000022$ (praktisch kostenlos!)
  Time: 400ms
```

## ğŸš€ Next Steps

1. **Test die Metriken**: Sende verschiedene Nachrichten
2. **Vergleiche Modelle**: Nutze verschiedene OpenRouter Models
3. **Monitoring**: Track deine Gesamtkosten Ã¼ber Zeit
4. **Optimierung**: WÃ¤hle gÃ¼nstigere Modelle fÃ¼r einfache Aufgaben

## â“ FAQs

**F: Warum sind die Metriken manchmal leer?**  
A: Bei Perplexity Provider gibt es noch keine Metriken. Nur bei OpenRouter.

**F: Ist die Cost-Berechnung genau?**  
A: Sie basiert auf ModelPricingConfig. Die API sendet auch eine Cost, die kann leicht abweichen.

**F: Kann ich die Metriken exportieren?**  
A: Noch nicht, aber das ist geplant!

**F: Warum dauert eine Antwort manchmal lÃ¤nger?**  
A: AbhÃ¤ngig von Modell-KomplexitÃ¤t, API-Last und Ihrer Frage-LÃ¤nge.

## ğŸ“š Weitere Dokumentation

- `MODEL_PRICING_FEATURE.md` - Pricing-System Details
- `MODEL_PRICING_EXAMPLES.md` - Kostenbeispiele fÃ¼r alle Modelle
- `METRICS_DISPLAY_IMPLEMENTATION.md` - Technische Implementierungsdetails

## âœ¨ Zusammenfassung

ğŸ‰ Deine API-Anfragen werden jetzt mit vollstÃ¤ndigen Metriken getracked!

Alle wichtigen Informationen sind sichtbar:
- ğŸ“Š Tokens: Wie viele wurden verwendet
- ğŸ’° Kosten: Wie viel hat die Anfrage gekostet
- â±ï¸ Zeit: Wie lange die API brauchte
- ğŸ¤– Model: Welches Model wurde verwendet

Viel SpaÃŸ beim Erkunden!

