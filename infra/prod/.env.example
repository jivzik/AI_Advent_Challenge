# ==================================
# AI Advent Challenge - Production Environment Variables
# ==================================

# Spring Profiles
SPRING_PROFILES_ACTIVE=prod

# ==================================
# PostgreSQL Database Configuration
# ==================================
POSTGRES_DB=ai_challenge_db
POSTGRES_USER=ai_user
POSTGRES_PASSWORD=CHANGE_ME_STRONG_PASSWORD_HERE

# ==================================
# Ollama Configuration
# ==================================
OLLAMA_MODEL=phi3:mini
OLLAMA_TIMEOUT_SECONDS=120

# ==================================
# OpenRouter API Configuration
# ==================================
OPENROUTER_API_KEY=YOUR_OPENROUTER_API_KEY_HERE

# ==================================
# GitHub Configuration (optional)
# ==================================
PERSONAL_GITHUB_TOKEN=
PERSONAL_GITHUB_REPOSITORY=

# ==================================
# Service-specific configurations
# ==================================

# LLM Chat Service
# Additional environment variables for llm-chat-service
# OLLAMA_BASE_URL is set to http://ollama:11434 in docker-compose.yml

# Notes:
# - POSTGRES_PASSWORD is required and must be set
# - OPENROUTER_API_KEY is required for most services
# - OLLAMA_MODEL can be changed to any supported Ollama model
# - GitHub token and repository are optional

